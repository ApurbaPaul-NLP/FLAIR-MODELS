{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE+ncVCyNNGKuW+tYRjxAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApurbaPaul-NLP/FLAIR-MODELS/blob/main/Prog2_06_09_2022_WordEmbeddings_FlairEmbeddings_StackedEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZlPwfEWqfl0",
        "outputId": "9dae0699-a8d1-4f64-f50e-5abdb24943a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 30.8 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.6 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 77.0 MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 65.7 MB/s \n",
            "\u001b[?25hCollecting conllu>=4.0\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 57.1 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.10)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.14.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2022.6.2)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 66.8 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.0.0\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.7.3)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.5.0)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (6.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=687f47ae0672e5e7dfd7233aad7b88125131f6c4b3304e8ddd85c288996d9bd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=1699f23541664720b30c166720f8f548132448b4a385c399aedb06e579cdab81\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=b81510b35f9a8f59bf7b887ad29c46ccfe0389bc8c5f985fb6e8445cad5c08bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=eee1efbca947cad4164eb58770bc80ce5bb18cd92461c21617fb191ad1fdcb1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=ba87d88815e246c52a38b73519bedeaa83d7c13625d2c23638baa18752f5a49c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=77627dd57cd46ab4bbe6361a9e68904086037a24bc5c683046e2c8fb9895fd04\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.12.0\n",
            "    Uninstalling importlib-metadata-4.12.0:\n",
            "      Successfully uninstalled importlib-metadata-4.12.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.5.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.9.1 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.7 requests-2.28.1 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.21.3 wikipedia-api-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install flair"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings**"
      ],
      "metadata": {
        "id": "Rtxq2ngDrUaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All word embedding classes inherit from the TokenEmbeddings class and implement the embed() method which you need to call to embed your text. \n",
        "\n",
        "This means that for most users of Flair, the complexity of different embeddings remains hidden behind this interface. \n",
        "\n",
        "Simply instantiate the embedding class you require and call embed() to embed your text. \n",
        "\n",
        "All embeddings produced with our methods are PyTorch vectors, so they can be immediately used for training and fine-tuning."
      ],
      "metadata": {
        "id": "lWQBdrk9rcc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classic Word Embeddings**"
      ],
      "metadata": {
        "id": "SiktaoM5rwYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classic word embeddings are static and word-level, meaning that each distinct word gets exactly one pre-computed embedding. \n",
        "\n",
        "Most embeddings fall under this class, including the popular GloVe or Komninos embeddings.\n",
        "\n",
        "Simply instantiate the WordEmbeddings class and pass a string identifier of the embedding you wish to load. \n",
        "\n",
        "So, if you want to use GloVe embeddings, pass the string 'glove' to the constructor:"
      ],
      "metadata": {
        "id": "c4EkgPlkryB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.data import Sentence\n",
        "\n",
        "# init embedding\n",
        "glove_embedding = WordEmbeddings('glove')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3L6pzZ3rgNM",
        "outputId": "2a789b91-ac74-4e11-b273-6f0d515ca127"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:02:36,406 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmp1o_z0abd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160000128/160000128 [00:13<00:00, 11795303.02B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:02:50,668 copying /tmp/tmp1o_z0abd to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:02:50,904 removing temp file /tmp/tmp1o_z0abd\n",
            "2022-09-06 17:02:51,589 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmps15xmtmu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21494764/21494764 [00:03<00:00, 6955381.20B/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:02:55,392 copying /tmp/tmps15xmtmu to cache at /root/.flair/embeddings/glove.gensim\n",
            "2022-09-06 17:02:55,420 removing temp file /tmp/tmps15xmtmu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence.\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# embed a sentence using glove.\n",
        "glove_embedding.embed(sentence)\n",
        "\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfT3Y9CiwRAA",
        "outputId": "ac5c4661-d376-4ae9-912d-ea086bf62431"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706], device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.8135,  0.9404, -0.2405, -0.1350,  0.0557,  0.3363,  0.0802, -0.1015,\n",
            "        -0.5478, -0.3537,  0.0734,  0.2587,  0.1987, -0.1433,  0.2507,  0.4281,\n",
            "         0.1950,  0.5346,  0.7424,  0.0578, -0.3178,  0.9436,  0.8145, -0.0824,\n",
            "         0.6166,  0.7284, -0.3262, -1.3641,  0.1232,  0.5373, -0.5123,  0.0246,\n",
            "         1.0822, -0.2296,  0.6039,  0.5541, -0.9610,  0.4803,  0.0022,  0.5591,\n",
            "        -0.1637, -0.8468,  0.0741, -0.6216,  0.0260, -0.5162, -0.0525, -0.1418,\n",
            "        -0.0161, -0.4972, -0.5534, -0.4037,  0.5096,  1.0276, -0.0840, -1.1179,\n",
            "         0.3226,  0.4928,  0.9488,  0.2040,  0.5388,  0.8397, -0.0689,  0.3136,\n",
            "         1.0450, -0.2267, -0.0896, -0.6427,  0.6443, -1.1001, -0.0096,  0.2668,\n",
            "        -0.3230, -0.6065,  0.0479, -0.1664,  0.8571,  0.2335,  0.2539,  1.2546,\n",
            "         0.5472, -0.1980, -0.7186,  0.2076, -0.2587, -0.3650,  0.0834,  0.6932,\n",
            "         0.1574,  1.0931,  0.0913, -1.3773, -0.2717,  0.7071,  0.1872, -0.3307,\n",
            "        -0.2836,  0.1030,  1.2228,  0.8374], device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635], device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-6.7907e-01,  3.4908e-01, -2.3984e-01, -9.9652e-01,  7.3782e-01,\n",
            "        -6.5911e-04,  2.8010e-01,  1.7287e-02, -3.6063e-01,  3.6955e-02,\n",
            "        -4.0395e-01,  2.4092e-02,  2.8958e-01,  4.0497e-01,  6.9992e-01,\n",
            "         2.5269e-01,  8.0350e-01,  4.9370e-02,  1.5562e-01, -6.3286e-03,\n",
            "        -2.9414e-01,  1.4728e-01,  1.8977e-01, -5.1791e-01,  3.6986e-01,\n",
            "         7.4582e-01,  8.2689e-02, -7.2601e-01, -4.0939e-01, -9.7822e-02,\n",
            "        -1.4096e-01,  7.1121e-01,  6.1933e-01, -2.5014e-01,  4.2250e-01,\n",
            "         4.8458e-01, -5.1915e-01,  7.7125e-01,  3.6685e-01,  4.9652e-01,\n",
            "        -4.1298e-02, -1.4683e+00,  2.0038e-01,  1.8591e-01,  4.9860e-02,\n",
            "        -1.7523e-01, -3.5528e-01,  9.4153e-01, -1.1898e-01, -5.1903e-01,\n",
            "        -1.1887e-02, -3.9186e-01, -1.7479e-01,  9.3451e-01, -5.8931e-01,\n",
            "        -2.7701e+00,  3.4522e-01,  8.6533e-01,  1.0808e+00, -1.0291e-01,\n",
            "        -9.1220e-02,  5.5092e-01, -3.9473e-01,  5.3676e-01,  1.0383e+00,\n",
            "        -4.0658e-01,  2.4590e-01, -2.6797e-01, -2.6036e-01, -1.4151e-01,\n",
            "        -1.2022e-01,  1.6234e-01, -7.4320e-01, -6.4728e-01,  4.7133e-02,\n",
            "         5.1642e-01,  1.9898e-01,  2.3919e-01,  1.2550e-01,  2.2471e-01,\n",
            "         8.2613e-01,  7.8328e-02, -5.7020e-01,  2.3934e-02, -1.5410e-01,\n",
            "        -2.5739e-01,  4.1262e-01, -4.6967e-01,  8.7914e-01,  7.2629e-01,\n",
            "         5.3862e-02, -1.1575e+00, -4.7835e-01,  2.0139e-01, -1.0051e+00,\n",
            "         1.1515e-01, -9.6609e-01,  1.2960e-01,  1.8388e-01, -3.0383e-02],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
            "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
            "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
            "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
            "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
            "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
            "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
            "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
            "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
            "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
            "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
            "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
            "        -0.3924, -0.2339,  0.4730, -0.0288], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**English-FastText Embedding**"
      ],
      "metadata": {
        "id": "2kBV2Mu0yuPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_embedding = WordEmbeddings('en-crawl')\n",
        "eng_embedding.embed(sentence)\n",
        "\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APFSgR22yJGF",
        "outputId": "3ec766a6-94f1-4d69-8dd9-bfd080e4d285"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:11:31,118 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-crawl-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpkmx4hysc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200000128/1200000128 [01:28<00:00, 13504330.31B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:13:00,654 copying /tmp/tmpkmx4hysc to cache at /root/.flair/embeddings/en-fasttext-crawl-300d-1M.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:13:04,932 removing temp file /tmp/tmpkmx4hysc\n",
            "2022-09-06 17:13:06,078 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-crawl-300d-1M not found in cache, downloading to /tmp/tmp1al25_f9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39323680/39323680 [00:04<00:00, 9352709.31B/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:13:10,946 copying /tmp/tmp1al25_f9 to cache at /root/.flair/embeddings/en-fasttext-crawl-300d-1M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:13:10,992 removing temp file /tmp/tmp1al25_f9\n",
            "Token[0]: \"The\"\n",
            "tensor([ 3.4100e-02,  2.3550e-01, -6.3600e-02, -2.6600e-02,  3.9000e-02,\n",
            "         1.8200e-02,  1.5850e-01, -3.9070e-01, -4.3700e-02, -4.8400e-02,\n",
            "        -1.0740e-01,  8.3800e-02, -2.5350e-01, -3.0200e-02, -1.5200e-01,\n",
            "        -2.3300e-02,  2.1290e-01, -1.2400e-02, -5.9100e-02,  4.3200e-02,\n",
            "        -2.9000e-03, -6.3700e-02,  8.1700e-02, -5.1700e-02,  5.1900e-02,\n",
            "         4.9900e-02, -1.5120e-01, -1.5300e-02, -5.8800e-02, -3.3890e-01,\n",
            "         3.1600e-02,  2.5000e-03,  1.7000e-02,  2.0200e-01,  2.9000e-02,\n",
            "        -2.1000e-03, -2.6000e-03,  5.3000e-02,  1.3900e-02,  1.2660e-01,\n",
            "         5.7500e-02, -2.5300e-02, -7.8000e-02, -1.8300e-02, -1.4100e-01,\n",
            "        -8.2000e-03,  4.2100e-02, -5.5000e-03, -1.9000e-03, -7.8200e-02,\n",
            "         2.3600e-02,  3.4040e-01, -1.3570e-01, -9.4500e-02, -2.3200e-02,\n",
            "         4.2600e-02,  5.9800e-02,  2.1380e-01,  1.0600e-02, -8.6500e-02,\n",
            "         2.4990e-01,  2.7580e-01,  1.0400e-01,  1.2040e-01, -1.4020e-01,\n",
            "        -1.0300e-02, -2.1500e-01,  2.8000e-03,  1.2580e-01,  1.1140e-01,\n",
            "        -3.1460e-01, -7.2900e-02, -7.0200e-02,  5.8500e-02, -1.1880e-01,\n",
            "         2.7060e-01, -1.6350e-01,  2.0660e-01,  3.0180e-01, -1.4190e-01,\n",
            "         1.3858e+00, -6.3400e-02,  3.0500e-02, -5.9600e-02,  1.5500e-01,\n",
            "         3.3100e-02,  1.0880e-01,  1.2620e-01, -8.1300e-02, -1.0400e-02,\n",
            "         2.9500e-02,  8.1410e-01,  4.3400e-02,  3.1000e-03,  1.6690e-01,\n",
            "         1.5860e-01,  6.7020e-01,  2.9540e-01,  6.1400e-02, -2.2500e-02,\n",
            "         1.8100e-02, -5.6400e-02, -2.8800e-02,  1.5880e-01, -1.5910e-01,\n",
            "        -3.9000e-03,  2.2260e-01,  1.1670e-01, -5.5400e-02,  2.3440e-01,\n",
            "        -5.6300e-02, -7.2190e-01,  1.5200e-02, -7.3900e-02, -1.4840e-01,\n",
            "         1.0640e-01, -2.2190e-01,  4.5800e-02,  1.8970e-01,  5.7300e-02,\n",
            "        -2.4300e-02, -8.2600e-02,  1.4700e-02,  2.2200e-02,  7.2300e-02,\n",
            "        -6.2000e-02,  3.2300e-02,  4.3300e-02,  6.9220e-01, -3.7500e-02,\n",
            "         1.3460e-01, -2.0000e-04,  1.1120e-01, -1.0060e-01, -6.3000e-03,\n",
            "        -1.4100e-02,  2.3790e-01,  4.8100e-02, -8.8200e-02, -6.3890e-01,\n",
            "         1.4750e-01,  1.3000e-03,  4.3800e-02,  8.8500e-02,  1.0900e-02,\n",
            "        -1.5610e-01,  1.1270e-01,  4.6000e-03, -9.5100e-02, -2.8900e-02,\n",
            "        -9.1700e-02,  4.5500e-02, -9.6000e-03, -3.0500e-02, -1.0090e-01,\n",
            "        -7.0600e-02,  8.5100e-02,  1.1090e-01, -3.8700e-02, -9.4900e-02,\n",
            "         3.6790e-01,  3.0900e-02,  6.3100e-02,  6.0200e-02, -1.8900e-02,\n",
            "        -1.2000e-03, -7.1000e-03, -5.7900e-02, -1.3130e-01,  4.1000e-03,\n",
            "        -6.2300e-02,  1.0660e-01, -1.3000e-03, -4.4900e-02,  3.1560e-01,\n",
            "         8.9000e-02, -8.4200e-02,  2.1000e-02,  2.4200e-02, -1.1300e-02,\n",
            "         5.8400e-02,  6.4000e-02,  1.1000e-03, -5.2100e-02,  5.4300e-02,\n",
            "         4.6300e-02,  1.9970e-01,  2.7700e-02,  6.5900e-02,  4.9300e-02,\n",
            "        -4.3400e-02,  2.0000e-02,  7.8000e-03, -9.6000e-02,  1.8000e-02,\n",
            "         9.9000e-03,  1.3640e-01,  1.0950e-01,  1.0040e-01,  1.1670e-01,\n",
            "        -1.3660e-01,  3.0400e-02, -2.1100e-02,  1.5480e-01, -8.4600e-02,\n",
            "         1.7300e-02,  2.2200e-02,  2.3300e-02,  1.8660e-01,  1.8450e-01,\n",
            "         1.6700e-02,  4.4670e-01, -1.7300e-02,  8.6900e-02, -4.6300e-02,\n",
            "        -1.0140e-01,  7.7300e-02, -5.0900e-02, -3.0100e-02, -6.4500e-02,\n",
            "         1.1040e-01,  6.7260e-01,  7.3000e-03,  4.8400e-02, -5.2800e-02,\n",
            "        -1.4290e-01,  5.0300e-02, -2.1300e-02, -8.6000e-02, -1.8100e-02,\n",
            "         8.7000e-02, -7.2000e-02,  4.5100e-02,  9.0100e-02, -3.5500e-02,\n",
            "         1.1100e-02,  1.0770e-01,  1.0000e-02, -1.1120e-01,  7.5200e-02,\n",
            "        -5.5200e-02, -6.7100e-02,  2.9600e-02, -1.2000e-03, -1.6260e-01,\n",
            "         6.4700e-02, -6.8500e-01,  1.9400e-02,  4.7700e-02,  4.6500e-02,\n",
            "         5.4600e-02,  1.0030e-01,  7.5000e-03, -2.4300e-02, -1.3780e-01,\n",
            "        -6.8900e-02,  8.5100e-02, -5.3400e-02, -5.3300e-02,  3.8200e-02,\n",
            "         1.3900e-02, -2.5100e-02,  1.3660e-01,  8.4800e-02,  7.8100e-02,\n",
            "         5.4100e-02, -5.2800e-02,  1.2000e-02, -4.4900e-02,  7.9900e-02,\n",
            "         1.3500e-02, -1.3730e-01, -6.8000e-03,  6.2100e-02, -2.8000e-03,\n",
            "        -4.1700e-02,  1.4930e-01, -8.3900e-02,  2.6000e-03,  1.6100e-02,\n",
            "         2.3720e-01,  3.3440e-01, -1.3660e-01,  5.6000e-02,  2.1400e-02,\n",
            "         3.6400e-02, -4.9000e-03,  1.8000e-02, -1.1410e-01, -1.1790e-01,\n",
            "        -6.0400e-02,  1.0200e-02, -2.8900e-02, -7.2480e-01,  8.2300e-02,\n",
            "        -4.1600e-02, -6.6400e-02,  3.9460e-01, -2.7500e-02,  1.5310e-01,\n",
            "        -3.8194e-02, -2.4487e-01,  7.2812e-01, -3.9961e-01,  8.3172e-02,\n",
            "         4.3953e-02, -3.9141e-01,  3.3440e-01, -5.7545e-01,  8.7459e-02,\n",
            "         2.8787e-01, -6.7310e-02,  3.0906e-01, -2.6384e-01, -1.3231e-01,\n",
            "        -2.0757e-01,  3.3395e-01, -3.3848e-01, -3.1743e-01, -4.8336e-01,\n",
            "         1.4640e-01, -3.7304e-01,  3.4577e-01,  5.2041e-02,  4.4946e-01,\n",
            "        -4.6971e-01,  2.6280e-02, -5.4155e-01, -1.5518e-01, -1.4107e-01,\n",
            "        -3.9722e-02,  2.8277e-01,  1.4393e-01,  2.3464e-01, -3.1021e-01,\n",
            "         8.6173e-02,  2.0397e-01,  5.2624e-01,  1.7164e-01, -8.2378e-02,\n",
            "        -7.1787e-01, -4.1531e-01,  2.0335e-01, -1.2763e-01,  4.1367e-01,\n",
            "         5.5187e-01,  5.7908e-01, -3.3477e-01, -3.6559e-01, -5.4857e-01,\n",
            "        -6.2892e-02,  2.6584e-01,  3.0205e-01,  9.9775e-01, -8.0481e-01,\n",
            "        -3.0243e+00,  1.2540e-02, -3.6942e-01,  2.2167e+00,  7.2201e-01,\n",
            "        -2.4978e-01,  9.2136e-01,  3.4514e-02,  4.6745e-01,  1.1079e+00,\n",
            "        -1.9358e-01, -7.4575e-02,  2.3353e-01, -5.2062e-02, -2.2044e-01,\n",
            "         5.7162e-02, -1.5806e-01, -3.0798e-01, -4.1625e-01,  3.7972e-01,\n",
            "         1.5006e-01, -5.3212e-01, -2.0550e-01, -1.2526e+00,  7.1624e-02,\n",
            "         7.0565e-01,  4.9744e-01, -4.2063e-01,  2.6148e-01, -1.5380e+00,\n",
            "        -3.0223e-01, -7.3438e-02, -2.8312e-01,  3.7104e-01, -2.5217e-01,\n",
            "         1.6215e-02, -1.7099e-02, -3.8984e-01,  8.7424e-01, -7.2569e-01,\n",
            "        -5.1058e-01, -5.2028e-01, -1.4590e-01,  8.2780e-01,  2.7062e-01],\n",
            "       device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([ 2.3400e-02, -3.0680e-01, -2.9780e-01, -5.9600e-02, -7.0570e-01,\n",
            "         3.8360e-01, -5.1440e-01,  7.7000e-03,  2.0850e-01, -2.1350e-01,\n",
            "        -1.6620e-01,  1.7930e-01, -1.0510e-01,  1.5510e-01, -2.2490e-01,\n",
            "         7.3800e-02, -2.8850e-01, -3.9900e-02,  2.1140e-01, -2.2840e-01,\n",
            "        -2.6640e-01,  1.8000e-01, -2.2000e-01,  6.8600e-01, -4.6040e-01,\n",
            "         1.6540e-01, -4.3600e-02, -1.0320e-01, -1.5520e-01, -3.2490e-01,\n",
            "         1.2140e-01, -6.5300e-02,  4.1200e-02, -3.7280e-01, -4.8870e-01,\n",
            "         3.4050e-01,  2.7880e-01,  1.6020e-01, -3.3460e-01, -1.0440e-01,\n",
            "         3.4160e-01, -2.5560e-01, -1.2370e-01,  2.4900e-02,  2.1570e-01,\n",
            "        -1.6470e-01,  2.4200e-02, -1.1410e-01,  2.3190e-01, -2.2970e-01,\n",
            "        -2.8400e-02,  2.2910e-01,  4.7830e-01,  2.8530e-01,  3.8070e-01,\n",
            "         2.8400e-02, -6.0300e-02,  2.9000e-03, -1.8090e-01,  1.6210e-01,\n",
            "         3.6500e-01, -3.6960e-01, -1.3440e-01, -5.5490e-01,  1.1410e-01,\n",
            "        -3.9160e-01, -1.5260e-01, -2.2380e-01, -1.7140e-01, -1.6470e-01,\n",
            "        -2.7400e-02, -3.5990e-01,  2.8380e-01,  2.0000e-01, -2.5110e-01,\n",
            "        -8.7200e-02, -2.9690e-01,  1.9850e-01,  5.1000e-03, -5.9260e-01,\n",
            "         2.5000e-01,  7.0420e-01,  2.3230e-01,  1.3030e-01,  6.1240e-01,\n",
            "        -3.6700e-02, -2.6800e-02,  4.9000e-03, -1.1950e-01,  1.8850e-01,\n",
            "        -8.7300e-02,  1.8180e-01,  4.6890e-01, -3.3660e-01, -2.8290e-01,\n",
            "        -2.2520e-01,  1.5590e-01, -3.8930e-01,  1.9100e-01, -5.5490e-01,\n",
            "        -1.6590e-01,  2.6670e-01, -3.1410e-01,  2.1290e-01,  1.8470e-01,\n",
            "         3.9700e-02,  1.9460e-01,  2.0920e-01, -1.3830e-01, -1.5610e-01,\n",
            "        -7.5000e-02, -2.3070e-01,  6.7900e-02,  3.1800e-01, -5.0890e-01,\n",
            "         2.5400e-01, -4.9700e-02,  9.4100e-02,  1.5750e-01, -3.8950e-01,\n",
            "         1.2960e-01, -1.9260e-01, -1.5400e-02,  1.7000e-01,  2.2940e-01,\n",
            "         3.1250e-01,  3.2220e-01, -9.7300e-02, -3.5300e-02, -3.7600e-02,\n",
            "        -7.0600e-02, -2.6500e-01,  3.8400e-01, -3.7500e-02, -6.7400e-02,\n",
            "        -2.2900e-01,  4.5800e-01, -3.7330e-01,  3.9350e-01, -3.3740e-01,\n",
            "        -2.2520e-01, -1.1170e-01,  1.5600e-02,  3.5050e-01, -1.4420e-01,\n",
            "        -2.3840e-01, -2.3810e-01,  2.3290e-01, -1.1540e-01, -1.4760e-01,\n",
            "         4.8800e-01,  4.4200e-02, -1.3830e-01,  1.7740e-01, -3.4570e-01,\n",
            "         1.5610e-01, -3.4240e-01,  9.7800e-02, -2.1350e-01,  9.7800e-02,\n",
            "         5.8170e-01, -1.6750e-01,  1.9990e-01, -4.6000e-03,  3.7100e-02,\n",
            "        -1.8300e-02,  4.1000e-01, -4.7500e-02, -4.8500e-02, -5.7700e-02,\n",
            "         7.4700e-02,  2.4260e-01, -1.9730e-01, -3.2800e-02,  2.6610e-01,\n",
            "        -2.2600e-02, -3.2130e-01, -1.5190e-01,  7.0500e-02, -1.3620e-01,\n",
            "         7.1900e-02,  9.2600e-02, -5.9100e-01,  2.1700e-02, -3.1820e-01,\n",
            "        -4.3190e-01, -4.1300e-02, -1.3870e-01,  4.2230e-01, -7.0600e-02,\n",
            "         1.4000e-02,  3.1970e-01,  4.3200e-01, -9.9900e-02,  5.0000e-04,\n",
            "        -1.6410e-01,  4.1630e-01, -1.2220e-01,  8.0900e-02, -8.7000e-02,\n",
            "        -5.8300e-01, -2.6810e-01, -2.2460e-01,  3.5000e-03,  4.6000e-03,\n",
            "        -1.2500e-02, -1.6760e-01,  5.0640e-01,  1.9960e-01,  2.4250e-01,\n",
            "         1.8110e-01,  5.9530e-01,  2.0600e-02,  3.5810e-01,  1.1400e-02,\n",
            "        -2.0400e-01,  2.7600e-02,  1.8600e-01, -7.9000e-03, -5.6700e-02,\n",
            "         4.1570e-01,  3.8080e-01, -3.4100e-02,  6.2800e-02, -1.5290e-01,\n",
            "        -4.7700e-02, -3.2930e-01, -7.5900e-02, -8.8800e-02, -3.8700e-02,\n",
            "        -3.1310e-01, -5.3550e-01, -2.5800e-01,  2.0110e-01,  1.9940e-01,\n",
            "        -6.7780e-01, -2.4580e-01,  4.5600e-02,  2.7630e-01, -7.0340e-01,\n",
            "         1.9450e-01,  5.6410e-01,  4.0680e-01,  8.4100e-02,  2.7950e-01,\n",
            "        -3.1850e-01,  2.7400e-01,  2.2200e-01, -8.2600e-02, -1.2630e-01,\n",
            "        -3.2200e-02,  2.3250e-01,  4.5600e-02, -4.0260e-01, -3.6800e-02,\n",
            "        -2.4900e-02,  3.6240e-01,  4.1420e-01, -2.4760e-01,  8.1300e-02,\n",
            "         7.0400e-02,  8.7000e-03, -9.0700e-02, -1.4200e-02, -1.0170e-01,\n",
            "         3.6000e-03, -1.8510e-01, -4.2830e-01, -2.1550e-01, -2.1940e-01,\n",
            "         5.1800e-02, -6.8000e-02, -3.6720e-01, -6.5000e-02, -4.5340e-01,\n",
            "         1.1180e-01,  1.3340e-01,  4.0330e-01, -4.8600e-02, -1.0220e-01,\n",
            "        -2.7200e-02,  2.1090e-01,  5.0920e-01,  1.3080e-01,  4.3570e-01,\n",
            "         1.5980e-01,  2.0390e-01,  1.6520e-01,  2.2100e-02,  8.2600e-02,\n",
            "         4.2970e-01,  2.4590e-01,  3.7400e-02,  1.0520e-01,  2.6420e-01,\n",
            "         3.8430e-01, -5.7300e-02, -5.1570e-01,  1.4750e-01,  1.8820e-01,\n",
            "        -8.1353e-01,  9.4042e-01, -2.4048e-01, -1.3501e-01,  5.5678e-02,\n",
            "         3.3625e-01,  8.0209e-02, -1.0148e-01, -5.4776e-01, -3.5365e-01,\n",
            "         7.3382e-02,  2.5868e-01,  1.9866e-01, -1.4328e-01,  2.5070e-01,\n",
            "         4.2814e-01,  1.9498e-01,  5.3456e-01,  7.4241e-01,  5.7816e-02,\n",
            "        -3.1781e-01,  9.4359e-01,  8.1450e-01, -8.2375e-02,  6.1658e-01,\n",
            "         7.2844e-01, -3.2623e-01, -1.3641e+00,  1.2320e-01,  5.3728e-01,\n",
            "        -5.1228e-01,  2.4590e-02,  1.0822e+00, -2.2959e-01,  6.0385e-01,\n",
            "         5.5415e-01, -9.6099e-01,  4.8033e-01,  2.2260e-03,  5.5913e-01,\n",
            "        -1.6365e-01, -8.4681e-01,  7.4079e-02, -6.2157e-01,  2.5967e-02,\n",
            "        -5.1621e-01, -5.2462e-02, -1.4177e-01, -1.6123e-02, -4.9719e-01,\n",
            "        -5.5345e-01, -4.0371e-01,  5.0956e-01,  1.0276e+00, -8.4000e-02,\n",
            "        -1.1179e+00,  3.2257e-01,  4.9281e-01,  9.4876e-01,  2.0403e-01,\n",
            "         5.3883e-01,  8.3972e-01, -6.8883e-02,  3.1361e-01,  1.0450e+00,\n",
            "        -2.2669e-01, -8.9601e-02, -6.4271e-01,  6.4429e-01, -1.1001e+00,\n",
            "        -9.5814e-03,  2.6682e-01, -3.2302e-01, -6.0652e-01,  4.7915e-02,\n",
            "        -1.6637e-01,  8.5712e-01,  2.3355e-01,  2.5395e-01,  1.2546e+00,\n",
            "         5.4716e-01, -1.9796e-01, -7.1863e-01,  2.0760e-01, -2.5875e-01,\n",
            "        -3.6499e-01,  8.3436e-02,  6.9317e-01,  1.5737e-01,  1.0931e+00,\n",
            "         9.1295e-02, -1.3773e+00, -2.7170e-01,  7.0708e-01,  1.8720e-01,\n",
            "        -3.3072e-01, -2.8359e-01,  1.0296e-01,  1.2228e+00,  8.3741e-01],\n",
            "       device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([-2.2050e-01,  1.4340e-01,  3.8000e-02, -1.0300e-02,  3.3500e-02,\n",
            "        -2.8100e-02, -5.8000e-03, -1.3920e-01, -2.4600e-02, -3.7700e-02,\n",
            "        -1.6230e-01,  1.0500e-01, -6.5600e-02, -5.7600e-02, -1.0110e-01,\n",
            "         2.2700e-02,  4.4300e-02,  1.1950e-01,  6.5700e-02,  7.8100e-02,\n",
            "        -9.7100e-02,  2.4700e-02,  9.6000e-03, -1.3310e-01,  5.9500e-02,\n",
            "        -2.2900e-02,  2.4600e-02,  3.6000e-03, -6.8000e-03, -1.5120e-01,\n",
            "        -1.1030e-01,  3.6000e-03, -1.7030e-01, -2.7350e-01,  9.3100e-02,\n",
            "        -2.8600e-02, -5.6100e-02,  1.6200e-02,  1.4820e-01, -3.8100e-02,\n",
            "         1.5900e-02, -3.9130e-01,  1.6200e-02, -4.4500e-02, -7.2500e-02,\n",
            "         5.7000e-03, -3.1500e-02, -3.2800e-02,  7.2000e-03, -2.2450e-01,\n",
            "        -8.0400e-02, -4.4930e-01,  7.7540e-01, -5.5700e-02, -1.6100e-01,\n",
            "         4.1600e-02, -2.8400e-02, -7.4700e-02, -5.8600e-02, -4.1400e-02,\n",
            "         5.1900e-02,  5.3720e-01,  6.7800e-02, -4.8200e-02, -3.2500e-02,\n",
            "         6.3800e-02, -6.4300e-02,  5.2600e-02, -5.1000e-03, -2.8700e-02,\n",
            "         9.6600e-02,  1.0100e-01,  1.3480e-01,  3.6090e-01, -6.1000e-03,\n",
            "         1.1270e-01, -9.6900e-02,  6.2200e-02,  2.9190e-01, -6.1500e-02,\n",
            "         7.5630e-01,  5.8200e-02, -1.2400e-02, -1.1960e-01,  7.5200e-02,\n",
            "        -9.0000e-03,  7.0300e-02,  6.4200e-02, -1.1650e-01,  1.9800e-02,\n",
            "        -2.8000e-03, -1.9000e-02,  6.9200e-02,  5.1500e-02,  7.1000e-02,\n",
            "         7.7100e-02, -5.0060e-01, -1.5400e-02, -7.6600e-02,  3.8300e-02,\n",
            "        -2.5000e-02, -3.6700e-02,  1.4110e-01,  7.5100e-02, -6.4400e-02,\n",
            "        -1.3860e-01,  2.9400e-02, -1.1840e-01, -6.6300e-02,  2.4020e-01,\n",
            "        -4.0100e-02,  2.4400e-02,  6.5000e-02, -3.2900e-02, -2.4960e-01,\n",
            "        -3.9200e-02, -6.2900e-02,  3.2200e-02,  1.7670e-01,  1.5700e-02,\n",
            "        -1.7060e-01, -5.0000e-04, -2.1720e-01,  1.2900e-02, -4.5700e-02,\n",
            "         3.0800e-02,  1.2800e-02,  1.1490e-01,  2.1680e-01, -1.8720e-01,\n",
            "         1.3800e-02, -2.8200e-02, -2.3200e-02,  1.2570e-01, -4.2220e-01,\n",
            "        -8.3800e-02,  1.1700e-02,  2.2000e-02,  1.7700e-01,  4.8370e-01,\n",
            "         1.4980e-01, -7.9800e-02,  3.2000e-03, -1.6220e-01,  1.5360e-01,\n",
            "        -8.3700e-02, -7.3100e-02, -9.5200e-02, -2.8500e-02, -1.6900e-02,\n",
            "         5.8900e-02,  1.5100e-02,  1.2380e-01,  7.2000e-03, -4.3500e-02,\n",
            "        -2.5600e-02, -2.2330e-01,  1.0800e-02,  1.2200e-01, -1.1410e-01,\n",
            "         9.9970e-01, -1.0260e-01,  1.5500e-02, -1.1100e-02,  9.9100e-02,\n",
            "        -4.1400e-02, -1.3000e-02, -8.9200e-02, -6.0000e-03, -9.3100e-02,\n",
            "         7.0000e-04,  8.4500e-02,  4.6200e-02,  1.4400e-02,  1.6220e-01,\n",
            "         1.2860e-01, -9.7600e-02, -1.1640e-01,  7.1400e-02, -1.1130e-01,\n",
            "         6.9650e-01, -5.8000e-02, -2.2200e-02, -1.7100e-02,  9.3500e-02,\n",
            "        -7.9900e-02,  1.4330e-01, -3.1350e-01, -1.0910e-01,  1.4200e-02,\n",
            "        -4.7700e-02,  9.8300e-02,  1.3370e-01, -1.2600e-02, -4.0000e-03,\n",
            "        -1.2000e-02, -6.2200e-02,  9.5300e-02,  1.5850e-01,  6.9300e-02,\n",
            "         2.4100e-02, -8.8400e-02,  6.4400e-02,  1.2650e-01, -6.1600e-02,\n",
            "         5.8800e-02, -1.5500e-02,  5.9900e-02,  1.7090e-01,  2.2680e-01,\n",
            "        -1.7000e-03,  6.5070e-01,  2.6000e-02,  4.9200e-02,  3.3200e-02,\n",
            "        -1.7210e-01,  1.1000e-02,  4.6700e-02,  1.3110e-01,  2.4500e-02,\n",
            "         1.4900e-02,  1.5510e-01, -1.0500e-02, -3.5700e-02, -7.7400e-02,\n",
            "        -1.0000e-03, -1.3800e-02,  7.7900e-02, -1.5640e-01,  8.8800e-02,\n",
            "        -7.0800e-02, -5.7300e-02,  3.2300e-02, -3.0700e-02, -4.2900e-02,\n",
            "         6.9100e-02,  1.4700e-01, -8.6000e-02, -9.3900e-02,  4.1200e-02,\n",
            "        -6.3500e-02, -1.0170e-01, -2.5300e-02, -8.1400e-02, -4.2080e-01,\n",
            "        -5.7000e-02,  1.4080e-01,  8.9000e-02,  1.3930e-01, -4.8700e-02,\n",
            "         2.5900e-02,  2.6400e-02, -3.4800e-02, -1.6000e-03,  2.9870e-01,\n",
            "        -1.0200e-02,  9.9700e-02, -4.7700e-02,  1.6900e-02, -1.8900e-02,\n",
            "         6.3500e-02, -3.3500e-02,  3.7000e-03, -3.9000e-02, -8.1200e-02,\n",
            "         9.9800e-02, -1.5560e-01,  8.4000e-02, -9.9700e-02, -1.0800e-02,\n",
            "         2.7800e-02, -2.6310e-01,  7.8800e-02,  1.7410e-01, -6.9800e-02,\n",
            "        -8.4600e-02,  1.5740e-01, -1.3120e-01,  1.1360e-01,  9.1800e-02,\n",
            "         3.5000e-03,  1.1190e-01, -7.2600e-02,  1.7000e-03,  5.6100e-02,\n",
            "         1.3180e-01,  8.2700e-02,  2.5400e-02, -7.7400e-02, -8.8300e-02,\n",
            "        -3.9000e-03,  5.5700e-02,  2.6600e-02,  2.3100e-01, -9.3000e-03,\n",
            "        -3.8980e-01,  3.0000e-02, -1.5600e-01,  1.8140e-01,  7.2000e-03,\n",
            "        -5.4264e-01,  4.1476e-01,  1.0322e+00, -4.0244e-01,  4.6691e-01,\n",
            "         2.1816e-01, -7.4864e-02,  4.7332e-01,  8.0996e-02, -2.2079e-01,\n",
            "        -1.2808e-01, -1.1440e-01,  5.0891e-01,  1.1568e-01,  2.8211e-02,\n",
            "        -3.6280e-01,  4.3823e-01,  4.7511e-02,  2.0282e-01,  4.9857e-01,\n",
            "        -1.0068e-01,  1.3269e-01,  1.6972e-01,  1.1653e-01,  3.1355e-01,\n",
            "         2.5713e-01,  9.2783e-02, -5.6826e-01, -5.2975e-01, -5.1456e-02,\n",
            "        -6.7326e-01,  9.2533e-01,  2.6930e-01,  2.2734e-01,  6.6365e-01,\n",
            "         2.6221e-01,  1.9719e-01,  2.6090e-01,  1.8774e-01, -3.4540e-01,\n",
            "        -4.2635e-01,  1.3975e-01,  5.6338e-01, -5.6907e-01,  1.2398e-01,\n",
            "        -1.2894e-01,  7.2484e-01, -2.6105e-01, -2.6314e-01, -4.3605e-01,\n",
            "         7.8908e-02, -8.4146e-01,  5.1595e-01,  1.3997e+00, -7.6460e-01,\n",
            "        -3.1453e+00, -2.9202e-01, -3.1247e-01,  1.5129e+00,  5.2435e-01,\n",
            "         2.1456e-01,  4.2452e-01, -8.8411e-02, -1.7805e-01,  1.1876e+00,\n",
            "         1.0579e-01,  7.6571e-01,  2.1914e-01,  3.5824e-01, -1.1636e-01,\n",
            "         9.3261e-02, -6.2483e-01, -2.1898e-01,  2.1796e-01,  7.4056e-01,\n",
            "        -4.3735e-01,  1.4343e-01,  1.4719e-01, -1.1605e+00, -5.0508e-02,\n",
            "         1.2677e-01, -1.4395e-02, -9.8676e-01, -9.1297e-02, -1.2054e+00,\n",
            "        -1.1974e-01,  4.7847e-02, -5.4001e-01,  5.2457e-01, -7.0963e-01,\n",
            "        -3.2528e-01, -1.3460e-01, -4.1314e-01,  3.3435e-01, -7.2412e-03,\n",
            "         3.2253e-01, -4.4219e-02, -1.2969e+00,  7.6217e-01,  4.6349e-01],\n",
            "       device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-1.3000e-02,  7.1300e-02, -3.3470e-01,  3.3300e-02, -5.9400e-02,\n",
            "         2.7950e-01, -1.7450e-01,  9.2600e-02,  3.2240e-01,  1.5800e-02,\n",
            "        -1.0920e-01,  6.2300e-02, -2.2200e-01, -2.1470e-01, -2.7840e-01,\n",
            "         8.0000e-03,  1.7100e-02, -1.5690e-01,  1.3810e-01, -2.0970e-01,\n",
            "         4.0200e-02, -1.4800e-02,  1.4190e-01,  4.6500e-02, -3.4140e-01,\n",
            "         1.6360e-01, -5.2700e-02, -2.3510e-01, -3.0360e-01, -2.1050e-01,\n",
            "        -1.7200e-02, -7.8600e-02,  5.9600e-02, -4.1950e-01, -1.5410e-01,\n",
            "         1.9510e-01,  1.9150e-01, -3.4350e-01, -8.2500e-02,  4.8200e-01,\n",
            "         1.2450e-01, -3.2590e-01, -2.9300e-01,  4.3700e-02,  1.0800e-01,\n",
            "        -2.7130e-01, -1.9530e-01, -3.2540e-01,  3.6290e-01, -4.2870e-01,\n",
            "         1.8230e-01,  3.8970e-01,  2.9310e-01, -1.1090e-01,  2.4780e-01,\n",
            "         1.4960e-01,  2.8190e-01, -1.6970e-01,  2.6400e-02, -6.8200e-02,\n",
            "         2.1180e-01, -3.9330e-01, -1.4080e-01, -1.8930e-01,  3.1080e-01,\n",
            "         3.6140e-01, -7.8300e-02, -1.2090e-01, -1.2320e-01, -3.9880e-01,\n",
            "         1.0300e-02,  2.0210e-01,  7.4830e-01,  3.2480e-01,  1.0980e-01,\n",
            "        -1.1600e-02, -4.3550e-01, -1.5730e-01,  2.2790e-01, -1.4870e-01,\n",
            "         2.8380e-01,  3.7940e-01, -1.0750e-01,  3.4350e-01,  1.1930e-01,\n",
            "         1.0920e-01,  1.0020e-01,  5.8600e-02,  1.5500e-01,  2.2800e-01,\n",
            "         2.2770e-01,  4.2600e-02,  3.7550e-01, -1.6250e-01,  1.0100e-01,\n",
            "        -2.7640e-01,  2.2460e-01, -7.9000e-02,  2.1460e-01, -1.8430e-01,\n",
            "         1.0080e-01,  2.1450e-01, -2.6220e-01,  1.4250e-01,  1.3840e-01,\n",
            "        -8.9300e-02, -7.0300e-02, -2.9400e-01,  1.6060e-01, -1.9370e-01,\n",
            "         1.9000e-01,  3.5700e-02, -2.9900e-02,  6.9500e-02, -5.8330e-01,\n",
            "         4.1220e-01,  5.8000e-02,  4.3000e-03,  1.0220e-01, -2.8800e-02,\n",
            "         3.7500e-02,  4.6500e-02,  9.6000e-02,  3.4860e-01,  5.3900e-02,\n",
            "         9.0300e-02, -2.1730e-01, -1.2030e-01,  1.8060e-01,  6.4100e-02,\n",
            "         1.9000e-03,  7.9300e-02,  1.8210e-01, -2.2200e-02, -2.7700e-02,\n",
            "         6.1000e-03,  2.4440e-01,  6.1700e-02,  8.7900e-02, -4.9520e-01,\n",
            "         2.7380e-01, -2.2130e-01, -5.6400e-02,  6.1400e-02, -6.2800e-02,\n",
            "        -3.6690e-01, -2.8660e-01, -2.9900e-02, -1.7200e-01, -1.0760e-01,\n",
            "         7.4600e-02,  3.6280e-01, -2.4320e-01, -2.7570e-01,  1.5120e-01,\n",
            "        -2.2200e-02,  2.1380e-01, -2.1230e-01, -5.1450e-01,  4.3030e-01,\n",
            "         2.0660e-01, -3.6400e-02,  8.4800e-02,  3.1810e-01,  5.6100e-02,\n",
            "        -1.2070e-01,  7.4600e-02, -2.3970e-01, -6.1100e-02, -1.0930e-01,\n",
            "         1.6500e-01,  1.5970e-01,  5.2500e-02, -2.3900e-01, -5.8500e-02,\n",
            "         2.5040e-01, -3.6270e-01,  5.7900e-02,  4.4460e-01,  1.6890e-01,\n",
            "        -1.0980e-01, -1.5590e-01, -8.1900e-02,  2.0500e-02,  1.4960e-01,\n",
            "        -6.5000e-02, -1.2720e-01,  7.7400e-02,  1.8220e-01,  1.0420e-01,\n",
            "        -5.2510e-01,  1.2740e-01,  1.4600e-02, -2.2090e-01,  5.9300e-02,\n",
            "        -4.7100e-02,  2.1800e-01, -9.6400e-02,  3.3740e-01,  1.3210e-01,\n",
            "        -2.5720e-01,  3.2300e-02,  2.2000e-03,  4.4400e-02,  2.7810e-01,\n",
            "        -1.4170e-01, -3.4590e-01,  1.5290e-01,  2.1970e-01,  1.9120e-01,\n",
            "        -5.7100e-02,  6.0440e-01, -2.8100e-02,  7.3000e-02, -1.4690e-01,\n",
            "         2.1040e-01,  2.2830e-01, -6.9200e-02,  4.0070e-01,  2.0400e-01,\n",
            "         1.6990e-01,  4.5470e-01, -1.0400e-02, -1.6400e-01, -4.8700e-02,\n",
            "        -6.6400e-02, -3.4610e-01,  8.9000e-02, -1.1870e-01, -1.2950e-01,\n",
            "        -3.1810e-01, -1.2940e-01, -3.6220e-01, -2.8530e-01,  4.5110e-01,\n",
            "        -2.4270e-01, -3.9080e-01, -2.9450e-01,  3.0360e-01,  3.5680e-01,\n",
            "         4.3810e-01,  4.4640e-01,  3.8520e-01, -1.2500e-01,  1.5460e-01,\n",
            "         1.0900e-02,  3.1780e-01,  5.5700e-02,  1.1160e-01,  3.6560e-01,\n",
            "        -1.5720e-01, -1.0890e-01,  2.1100e-02,  2.4820e-01,  2.2270e-01,\n",
            "        -2.0280e-01, -1.3160e-01, -1.7290e-01, -3.7200e-01,  2.6660e-01,\n",
            "        -1.9670e-01, -2.7370e-01, -5.8700e-02, -5.8000e-02, -8.5400e-02,\n",
            "        -4.3800e-02,  2.1930e-01, -1.0020e-01, -3.5090e-01, -4.0610e-01,\n",
            "         6.1400e-02,  9.2200e-02,  2.1000e-02,  2.4330e-01,  9.2200e-02,\n",
            "         3.3190e-01,  1.5230e-01,  3.8820e-01, -2.3770e-01,  7.6900e-02,\n",
            "        -1.5930e-01,  1.7180e-01,  6.6800e-02, -2.1800e-01,  2.1580e-01,\n",
            "        -2.8300e-01, -7.3000e-02,  4.3060e-01,  4.0800e-02,  6.6100e-02,\n",
            "         1.4270e-01, -2.9200e-02, -1.6030e-01,  1.5190e-01, -9.0900e-02,\n",
            "         1.0050e-01,  1.0000e-02, -2.0450e-01,  6.3500e-02, -8.3900e-02,\n",
            "        -6.7907e-01,  3.4908e-01, -2.3984e-01, -9.9652e-01,  7.3782e-01,\n",
            "        -6.5911e-04,  2.8010e-01,  1.7287e-02, -3.6063e-01,  3.6955e-02,\n",
            "        -4.0395e-01,  2.4092e-02,  2.8958e-01,  4.0497e-01,  6.9992e-01,\n",
            "         2.5269e-01,  8.0350e-01,  4.9370e-02,  1.5562e-01, -6.3286e-03,\n",
            "        -2.9414e-01,  1.4728e-01,  1.8977e-01, -5.1791e-01,  3.6986e-01,\n",
            "         7.4582e-01,  8.2689e-02, -7.2601e-01, -4.0939e-01, -9.7822e-02,\n",
            "        -1.4096e-01,  7.1121e-01,  6.1933e-01, -2.5014e-01,  4.2250e-01,\n",
            "         4.8458e-01, -5.1915e-01,  7.7125e-01,  3.6685e-01,  4.9652e-01,\n",
            "        -4.1298e-02, -1.4683e+00,  2.0038e-01,  1.8591e-01,  4.9860e-02,\n",
            "        -1.7523e-01, -3.5528e-01,  9.4153e-01, -1.1898e-01, -5.1903e-01,\n",
            "        -1.1887e-02, -3.9186e-01, -1.7479e-01,  9.3451e-01, -5.8931e-01,\n",
            "        -2.7701e+00,  3.4522e-01,  8.6533e-01,  1.0808e+00, -1.0291e-01,\n",
            "        -9.1220e-02,  5.5092e-01, -3.9473e-01,  5.3676e-01,  1.0383e+00,\n",
            "        -4.0658e-01,  2.4590e-01, -2.6797e-01, -2.6036e-01, -1.4151e-01,\n",
            "        -1.2022e-01,  1.6234e-01, -7.4320e-01, -6.4728e-01,  4.7133e-02,\n",
            "         5.1642e-01,  1.9898e-01,  2.3919e-01,  1.2550e-01,  2.2471e-01,\n",
            "         8.2613e-01,  7.8328e-02, -5.7020e-01,  2.3934e-02, -1.5410e-01,\n",
            "        -2.5739e-01,  4.1262e-01, -4.6967e-01,  8.7914e-01,  7.2629e-01,\n",
            "         5.3862e-02, -1.1575e+00, -4.7835e-01,  2.0139e-01, -1.0051e+00,\n",
            "         1.1515e-01, -9.6609e-01,  1.2960e-01,  1.8388e-01, -3.0383e-02],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([-8.4900e-02, -5.8200e-02, -3.2100e-02,  4.8300e-02, -1.8500e-02,\n",
            "        -8.3600e-02,  3.5500e-02, -4.9000e-03,  4.0800e-02,  6.2000e-02,\n",
            "        -6.9100e-02,  1.9640e-01,  2.6200e-02, -1.1290e-01,  3.7000e-03,\n",
            "        -4.1500e-02,  8.2100e-02, -5.8700e-02, -6.1900e-02, -5.0000e-03,\n",
            "        -1.9400e-02, -5.5700e-02,  3.3000e-03,  2.5900e-02, -2.0000e-02,\n",
            "         4.5700e-02, -3.2000e-03, -5.4900e-02, -7.6300e-02,  9.8200e-02,\n",
            "        -1.6100e-02, -1.2300e-02, -8.0100e-02, -4.7700e-02,  5.5900e-02,\n",
            "         4.1000e-03, -4.4000e-02,  4.4700e-02, -7.2500e-02,  1.3370e-01,\n",
            "         3.1000e-03,  2.2600e-02, -2.3800e-02, -5.2310e-01, -9.6100e-02,\n",
            "        -4.4700e-02,  8.5300e-02,  4.0000e-02, -2.9800e-02, -2.1250e-01,\n",
            "        -3.1700e-02,  1.2550e-01,  1.0590e-01, -3.3600e-02, -3.4300e-02,\n",
            "         1.0630e-01,  5.0000e-03,  2.6300e-01,  2.4000e-03, -9.0200e-02,\n",
            "        -4.6400e-02,  1.5660e-01,  2.3000e-03, -1.3400e-02, -4.3000e-02,\n",
            "        -1.3720e-01,  2.7700e-02,  6.2900e-02,  2.9300e-02,  2.2340e-01,\n",
            "        -4.4120e-01, -2.2700e-02, -1.2400e-02,  1.7250e-01, -1.0770e-01,\n",
            "        -1.3000e-03, -9.1330e-01,  9.1800e-02, -7.3100e-02, -1.9200e-02,\n",
            "         3.9050e-01, -1.5100e-02, -2.5000e-02,  3.4300e-02, -5.8000e-02,\n",
            "        -4.0000e-02,  7.4900e-02,  4.3000e-03, -3.9600e-02, -4.8500e-02,\n",
            "         2.5900e-02,  2.1280e-01,  1.1300e-02,  7.1000e-03, -1.4500e-02,\n",
            "         1.5900e-02,  1.9430e-01,  6.0000e-03, -5.6000e-03, -9.3600e-02,\n",
            "        -1.7500e-02,  4.5300e-02,  1.8510e-01,  9.6500e-02,  7.2600e-02,\n",
            "         1.0100e-02,  6.1000e-02,  7.4100e-02, -3.1000e-03,  2.3740e-01,\n",
            "         2.1900e-02, -3.5500e-01,  2.4100e-02, -2.5100e-02, -6.9880e-01,\n",
            "        -6.5900e-02,  1.6130e-01,  2.2900e-02, -1.0410e-01, -4.3900e-02,\n",
            "        -1.2820e-01, -6.3700e-02,  2.9100e-02,  8.4000e-03,  7.2500e-02,\n",
            "         2.3000e-03,  3.4800e-02,  5.2000e-02,  3.2310e-01,  8.3100e-02,\n",
            "        -8.1200e-02, -5.8500e-02,  2.5900e-02, -8.3900e-02, -1.5810e-01,\n",
            "         2.2900e-02, -1.0540e-01, -4.4700e-02,  7.0000e-04,  1.5800e-01,\n",
            "        -2.5000e-02, -5.2000e-02,  2.1200e-02,  2.8720e-01,  2.5400e-02,\n",
            "        -8.9100e-02,  1.5880e-01, -5.8000e-03,  1.4500e-02,  6.5100e-02,\n",
            "        -1.1200e-02, -2.3400e-02,  1.8500e-02, -2.0100e-02, -1.1410e-01,\n",
            "        -9.2800e-02, -1.5340e-01,  9.6200e-02,  2.8300e-02, -1.4500e-02,\n",
            "         7.3860e-01, -5.5000e-02, -1.2090e-01, -1.2350e-01, -1.3300e-02,\n",
            "        -3.8200e-02, -6.9000e-03, -1.4590e-01, -8.6200e-02, -6.2200e-02,\n",
            "        -3.6400e-02, -5.7800e-02,  1.2190e-01, -1.3400e-02,  1.2000e-01,\n",
            "        -1.8900e-02,  1.9500e-02,  8.6100e-02,  7.2000e-02,  4.4200e-02,\n",
            "        -1.1970e-01, -3.4200e-02,  2.0700e-02, -3.4000e-03,  2.8900e-02,\n",
            "         5.4700e-02,  8.8400e-02,  4.1700e-02,  3.1800e-02,  9.3000e-02,\n",
            "        -6.1800e-02, -3.5000e-02,  4.4000e-02, -1.5280e-01,  1.1900e-02,\n",
            "         4.9000e-03, -8.3600e-02,  5.1000e-03,  2.5000e-03, -2.0000e-03,\n",
            "        -9.8400e-02, -1.0700e-02,  1.6500e-02,  6.4500e-02,  5.3700e-02,\n",
            "         4.9000e-02, -3.4700e-02, -1.6480e-01,  2.4600e-02,  1.2090e-01,\n",
            "        -4.3200e-02,  5.2240e-01,  8.8600e-02,  5.3100e-02,  1.0100e-02,\n",
            "        -4.6300e-02,  3.6600e-02,  2.5300e-02,  1.0610e-01, -9.4000e-02,\n",
            "         3.2800e-02, -4.2220e-01,  4.6400e-02, -4.4500e-02, -9.5900e-02,\n",
            "        -3.4500e-02,  4.8400e-02, -1.0100e-02,  6.9400e-02,  1.0500e-02,\n",
            "        -6.3200e-02,  2.3300e-02,  4.0000e-03,  4.8700e-02,  5.9000e-03,\n",
            "         1.4830e-01, -5.0000e-04,  1.6100e-02, -2.2600e-02, -2.2700e-02,\n",
            "         3.7000e-03, -7.4400e-02, -1.3200e-02, -6.7400e-02, -4.3700e-02,\n",
            "        -3.2000e-03, -8.3500e-01,  4.1600e-02, -2.2200e-02, -4.3000e-02,\n",
            "         7.2100e-02, -3.8500e-02, -7.7900e-02,  8.0600e-02, -5.5300e-02,\n",
            "         7.2900e-02, -5.9000e-02, -1.6000e-02, -1.2710e-01,  4.4700e-02,\n",
            "        -4.1800e-02, -4.5500e-02, -5.5000e-03,  5.6200e-02,  9.9200e-02,\n",
            "         8.9500e-02, -5.7900e-02, -5.4300e-02, -8.0900e-02,  1.1970e-01,\n",
            "         6.6000e-03,  1.0380e-01, -3.1500e-02, -3.0500e-02, -6.0700e-02,\n",
            "        -9.2000e-02,  6.0100e-02, -1.2850e-01, -5.0500e-02, -4.2000e-02,\n",
            "         1.0330e-01, -4.8180e-01, -3.3000e-03, -1.0200e-02,  5.0000e-03,\n",
            "         5.6500e-02, -1.6000e-02,  2.3000e-03, -9.2800e-02, -1.3180e-01,\n",
            "         1.3300e-02,  3.4400e-02,  1.8600e-02, -4.9950e-01, -1.3000e-02,\n",
            "         6.3300e-02, -3.3000e-02,  3.2000e-03, -2.3700e-02, -3.6600e-02,\n",
            "        -3.3979e-01,  2.0941e-01,  4.6348e-01, -6.4792e-01, -3.8377e-01,\n",
            "         3.8034e-02,  1.7127e-01,  1.5978e-01,  4.6619e-01, -1.9169e-02,\n",
            "         4.1479e-01, -3.4349e-01,  2.6872e-01,  4.4640e-02,  4.2131e-01,\n",
            "        -4.1032e-01,  1.5459e-01,  2.2239e-02, -6.4653e-01,  2.5256e-01,\n",
            "         4.3136e-02, -1.9445e-01,  4.6516e-01,  4.5651e-01,  6.8588e-01,\n",
            "         9.1295e-02,  2.1875e-01, -7.0351e-01,  1.6785e-01, -3.5079e-01,\n",
            "        -1.2634e-01,  6.6384e-01, -2.5820e-01,  3.6542e-02, -1.3605e-01,\n",
            "         4.0253e-01,  1.4289e-01,  3.8132e-01, -1.2283e-01, -4.5886e-01,\n",
            "        -2.5282e-01, -3.0432e-01, -1.1215e-01, -2.6182e-01, -2.2482e-01,\n",
            "        -4.4554e-01,  2.9910e-01, -8.5612e-01, -1.4503e-01, -4.9086e-01,\n",
            "         8.2973e-03, -1.7491e-01,  2.7524e-01,  1.4401e+00, -2.1239e-01,\n",
            "        -2.8435e+00, -2.7958e-01, -4.5722e-01,  1.6386e+00,  7.8808e-01,\n",
            "        -5.5262e-01,  6.5000e-01,  8.6426e-02,  3.9012e-01,  1.0632e+00,\n",
            "        -3.5379e-01,  4.8328e-01,  3.4600e-01,  8.4174e-01,  9.8707e-02,\n",
            "        -2.4213e-01, -2.7053e-01,  4.5287e-02, -4.0147e-01,  1.1395e-01,\n",
            "         6.2226e-03,  3.6673e-02,  1.8518e-02, -1.0213e+00, -2.0806e-01,\n",
            "         6.4072e-01, -6.8763e-02, -5.8635e-01,  3.3476e-01, -1.1432e+00,\n",
            "        -1.1480e-01, -2.5091e-01, -4.5907e-01, -9.6819e-02, -1.7946e-01,\n",
            "        -6.3351e-02, -6.7412e-01, -6.8895e-02,  5.3604e-01, -8.7773e-01,\n",
            "         3.1802e-01, -3.9242e-01, -2.3394e-01,  4.7298e-01, -2.8803e-02],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flair Embeddings**"
      ],
      "metadata": {
        "id": "UdjWJRhuy3pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contextual string embeddings are powerful embeddings that capture latent syntactic-semantic information that goes beyond standard word embeddings. \n",
        "\n",
        "Key differences are: \n",
        "\n",
        "    (1) they are trained without any explicit notion of words and thus fundamentally model words as sequences of characters. And \n",
        "    (2) they are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use.\n",
        "\n",
        "With Flair, you can use these embeddings simply by instantiating the appropriate embedding class, same as standard word embeddings:"
      ],
      "metadata": {
        "id": "sWGIID4MzRxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "# init embedding\n",
        "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
        "\n",
        "# create a sentence\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# embed words in sentence\n",
        "flair_embedding_forward.embed(sentence)\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0cbwZSpy46D",
        "outputId": "1e915939-945f-49f4-b8d8-685f936e945d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:17:18,448 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpl4v3ylan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73034624/73034624 [00:07<00:00, 10411923.71B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:17:26,127 copying /tmp/tmpl4v3ylan to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:17:26,227 removing temp file /tmp/tmpl4v3ylan\n",
            "Token[0]: \"The\"\n",
            "tensor([-0.0021,  0.0005,  0.0469,  ..., -0.0004, -0.0393,  0.0106],\n",
            "       device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.0006,  0.0047,  0.0248,  ..., -0.0004, -0.0236,  0.0117],\n",
            "       device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([ 0.0011, -0.0032,  0.0156,  ..., -0.0061,  0.0112,  0.0100],\n",
            "       device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.0034,  0.0003,  0.0256,  ..., -0.0026, -0.0118,  0.0455],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([ 0.0008,  0.0002,  0.1262,  ..., -0.0002,  0.0039,  0.0058],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward and Backeard Flair EMbeddings**"
      ],
      "metadata": {
        "id": "INdwuSSrzx4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init forward embedding for German\n",
        "flair_embedding_forward = FlairEmbeddings('en-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('en-backward')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27TnBsm0z3Bt",
        "outputId": "40fcf5d1-8c39-447b-93aa-7fe8c0472829"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:18:47,792 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpv65eg9q5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73034575/73034575 [00:07<00:00, 10397501.73B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:18:55,525 copying /tmp/tmpv65eg9q5 to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-06 17:18:55,658 removing temp file /tmp/tmpv65eg9q5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embed words in sentence\n",
        "flair_embedding_forward.embed(sentence)\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9Lh8Sgiz9sl",
        "outputId": "305c0b0e-894d-4a29-ae09-4d949102a369"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0021,  0.0005,  0.0469,  ..., -0.0004, -0.0393,  0.0106],\n",
            "       device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.0006,  0.0047,  0.0248,  ..., -0.0004, -0.0236,  0.0117],\n",
            "       device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([ 0.0011, -0.0032,  0.0156,  ..., -0.0061,  0.0112,  0.0100],\n",
            "       device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.0034,  0.0003,  0.0256,  ..., -0.0026, -0.0118,  0.0455],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([ 0.0008,  0.0002,  0.1262,  ..., -0.0002,  0.0039,  0.0058],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flair_embedding_backward.embed(sentence)\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8Diq6TC0DAV",
        "outputId": "a5d2218c-3d60-4ff9-86ba-6fa58427a29b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([ 0.0085, -0.0139, -0.0008,  ..., -0.0004, -0.0393,  0.0106],\n",
            "       device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([ 0.0049, -0.0203,  0.0007,  ..., -0.0004, -0.0236,  0.0117],\n",
            "       device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([ 0.0045,  0.0119, -0.0011,  ..., -0.0061,  0.0112,  0.0100],\n",
            "       device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.0012, -0.0028,  0.0070,  ..., -0.0026, -0.0118,  0.0455],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([-0.0008, -0.0064, -0.0006,  ..., -0.0002,  0.0039,  0.0058],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stacked Embeddings**"
      ],
      "metadata": {
        "id": "FeS3O1xP0NCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacked embeddings are one of the most important concepts of this library. You can use them to combine different embeddings together, for instance if you want to use both traditional embeddings together with contextual string embeddings. Stacked embeddings allow you to mix and match. \n",
        "\n",
        "We find that a combination of embeddings often gives best results.\n",
        "\n",
        "All you need to do is use the StackedEmbeddings class and instantiate it by passing a list of embeddings that you wish to combine. \n",
        "\n",
        "For instance, lets combine classic GloVe embeddings with forward and backward Flair embeddings. \n",
        "\n",
        "This is a combination that we generally recommend to most users, especially for sequence labeling.\n",
        "\n",
        "First, instantiate the two embeddings you wish to combine:"
      ],
      "metadata": {
        "id": "NO9NUMtn0TEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "# init standard GloVe embedding\n",
        "glove_embedding = WordEmbeddings('glove')\n",
        "\n",
        "# init Flair forward and backwards embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
        "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
        "stacked_embeddings = StackedEmbeddings([\n",
        "                                        glove_embedding,\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                       ])\n",
        "\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
        "stacked_embeddings.embed(sentence)\n",
        "\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQC8NKFN0X39",
        "outputId": "d616c8e6-cba2-4aa1-c9df-792ec6150d7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281,  ..., -0.0065, -0.0053,  0.0090],\n",
            "       device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.8135,  0.9404, -0.2405,  ...,  0.0354, -0.0255, -0.0143],\n",
            "       device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([-5.4264e-01,  4.1476e-01,  1.0322e+00,  ..., -5.3691e-04,\n",
            "        -9.6750e-03, -2.7541e-02], device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0007, -0.1333,  0.0161],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635,  ...,  0.0005, -0.0177,  0.0032],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words are now embedded using a concatenation of three different embeddings.\n",
        "\n",
        "This means that the resulting embedding vector is still a single PyTorch vector."
      ],
      "metadata": {
        "id": "PNQcFHCS0tk2"
      }
    }
  ]
}